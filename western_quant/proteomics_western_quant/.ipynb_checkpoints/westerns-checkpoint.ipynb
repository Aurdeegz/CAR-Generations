{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the module: helpers.general_helpers\n",
      "\n",
      "Loading the module: helpers.stats_helpers.py\n",
      "\n",
      "numpy        2.2.5\n",
      "scipy         1.15.2\n",
      "pandas        2.2.3\n",
      "\n",
      "Loading the module: helpers.mpl_plotting_helpers\n",
      "\n",
      "Loading the module: helpers.argcheck_helpers\n",
      "\n",
      "Loading the module: helpers.pandas_helpers\n",
      "\n",
      "pandas        2.2.3\n",
      "numpy         2.2.5\n",
      "\n",
      "matplotlib    3.10.1\n",
      "numpy         2.2.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importables\n",
    "\n",
    "from helpers import general_helpers as gh\n",
    "from helpers import stats_helpers as sh\n",
    "from helpers import mpl_plotting_helpers as mph\n",
    "from helpers import western_helpers as wh\n",
    "from helpers.mph_modules.dotplots import get_data_info, add_errorbar\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from math import log2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as mpl_fm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#\n",
    "# Making line plots and doing the statistics\n",
    "#  #  #  # Add to mpl_plotting_helpers at some point\n",
    "\n",
    "def _logical_ignore_comps(labelled_line_groups,\n",
    "                          group_strs,\n",
    "                          xgroup_strs):\n",
    "    \"\"\"\n",
    "    Only want to compare along a line group (e.g. timecourse) or\n",
    "    down an x-column (e.g. JE6 DMSO 0m vs JE6 U0126 0m), but not\n",
    "    all the random other comparisons because statistically they're\n",
    "    kind of useless\n",
    "    \n",
    "    So this function will find all of the pairs that are useless\n",
    "    \"\"\"\n",
    "    groups_unpacked = []\n",
    "    for group in labelled_line_groups:\n",
    "        groups_unpacked += group\n",
    "    # This will hold the ignored pairs\n",
    "    ignore_me_senpai = []\n",
    "    # First, get all pairs\n",
    "    paired = gh.make_pairs(groups_unpacked,\n",
    "                           dupes = False,\n",
    "                           reverse = False)\n",
    "    # Then iterate over and check the labels\n",
    "    for p in paired:\n",
    "        gs_check = 0\n",
    "        xs_check = 0\n",
    "        # Check all the group strings\n",
    "        for gs in group_strs:\n",
    "            if gs_check == 1:\n",
    "                pass\n",
    "            elif gs in p[0][0] and gs in p[1][0]:\n",
    "                gs_check = 1\n",
    "        # Check all the xgroup strings\n",
    "        for xs in xgroup_strs:\n",
    "            if xs_check == 1:\n",
    "                pass\n",
    "            elif xs in p[0][0] and xs in p[1][0]:\n",
    "                xs_check = 1\n",
    "        # If there isn't a match, in either, ignore\n",
    "        if gs_check == 0 and xs_check == 0:\n",
    "            ignore_me_senpai.append(p)\n",
    "    # Return the ignored pairs at the end\n",
    "    return ignore_me_senpai\n",
    "\n",
    "def perform_line_statistics(labelled_line_groups,\n",
    "                            ignore_comps,\n",
    "                            comp_type,\n",
    "                            statsfile):\n",
    "    \"\"\"\n",
    "    labelled_line_groups -> data with labels\n",
    "                            list of lists of [label, [d1,d2,...,dn]]\n",
    "    ignore_comps -> list of pairs (\"group 1\", \"group 2\") to not be\n",
    "                    compared\n",
    "    comp_type -> statistics to use, currently only\n",
    "                 [\"HolmSidak\", \"TukeyHSD\"] are supported\n",
    "                 (both do an ANOVA first by default)\n",
    "    statsfile -> a string to the output path and filename\n",
    "                 for the statistics file output\n",
    "    #####\n",
    "    Returns None, just dumps the statsfile\n",
    "    \"\"\"\n",
    "    assert comp_type in [\"HolmSidak\", \"TukeyHSD\"], f\"Invalid comparison type: {comp_type}\"\n",
    "    groups_unpacked = []\n",
    "    for group in labelled_line_groups:\n",
    "        groups_unpacked += group\n",
    "    if comp_type == \"HolmSidak\":\n",
    "        comparison = sh.HolmSidak(*groups_unpacked,\n",
    "                                  labels = True,\n",
    "                                  override = True,\n",
    "                                  alpha = 0.05,\n",
    "                                  no_comp = ignore_comps)\n",
    "    elif comp_type == \"TukeyHSD\":\n",
    "        comparison = sh.TukeyHSD(*groups_unpacked,\n",
    "                                  labels = True,\n",
    "                                  override = True,\n",
    "                                  alpha = 0.05,\n",
    "                                  no_comp = ignore_comps)\n",
    "    comparison.write_output(filename = statsfile,\n",
    "                            file_type = \"csv\")\n",
    "    return None\n",
    "\n",
    "def find_centres(plotting_info):\n",
    "    \"\"\"\n",
    "    plotting_info -> output from get_data_info, a list of\n",
    "                     data info and the raw data\n",
    "                     \n",
    "    goal: grab the centres for xticks\n",
    "    \"\"\"\n",
    "    centres = []\n",
    "    for group in plotting_info:\n",
    "        if len(centres) <= len(group[0][\"centers\"]):\n",
    "            centres = group[0][\"centers\"]\n",
    "    return centres\n",
    "\n",
    "def line_plot(labelled_line_groups,\n",
    "              show_points = False,\n",
    "              show_legend = False,\n",
    "              colours = [\"grey\" for _ in range(20)],\n",
    "              group_labs = [f\"Thing {i}\" for i in range(20)],\n",
    "              markers = [\"s\" for _ in range(20)],\n",
    "              linestyles = [\"solid\" for _ in range(20)],\n",
    "              xlabels = [f\"Time {i}\" for i in range(20)],\n",
    "              ylabel = [\"Fold change\"],\n",
    "              ylims = None,\n",
    "              ignore_comps = [],\n",
    "              statsfile = None,\n",
    "              comp_type = \"HolmSidak\",\n",
    "              figfile = None):\n",
    "    \"\"\"\n",
    "    labelled_line_groups -> list of lists, where each sublist contains labelled groups\n",
    "    \"\"\"\n",
    "    # First, get some basic plotting information\n",
    "    plotting_info = [get_data_info(line) for line in labelled_line_groups]\n",
    "    # Then manage the statistics\n",
    "    if statsfile != None:\n",
    "        perform_line_statistics(labelled_line_groups, \n",
    "                                ignore_comps, \n",
    "                                comp_type, \n",
    "                                statsfile)\n",
    "    # Begin plotting c::\n",
    "    if ylims == None:\n",
    "        ylims = floor(min([item for item in gh.unpack_list(labelled_line_groups) if type(item) in [int, float]])), ceil(max([item for item in gh.unpack_list(labelled_line_groups) if type(item) in [int, float]]))\n",
    "    # \n",
    "    fig, ax = plt.subplots(figsize = (6,6))\n",
    "    # \n",
    "    for i in range(len(labelled_line_groups)):\n",
    "        #\n",
    "        ax.plot(plotting_info[i][0][\"centers\"],\n",
    "                plotting_info[i][0][\"means\"],\n",
    "                color = colours[i],\n",
    "                label = group_labs[i],\n",
    "                linestyle = linestyles[i])\n",
    "        #\n",
    "        for j in range(len(labelled_line_groups[i])):\n",
    "            add_errorbar(ax, \n",
    "                         plotting_info[i][0][\"centers\"][j],\n",
    "                         plotting_info[i][0][\"means\"][j],\n",
    "                         plotting_info[i][0][\"sems\"][j],\n",
    "                         color = colours[i])\n",
    "            if show_points:\n",
    "            #\n",
    "                ax.scatter(plotting_info[i][0][\"xs\"][j],\n",
    "                           plotting_info[i][1][j][1],\n",
    "                           color = colours[i],\n",
    "                           edgecolor = \"black\", alpha = 0.3,\n",
    "                           marker = markers[i],\n",
    "                           s = 10)\n",
    "            else:\n",
    "            #\n",
    "                ax.scatter(plotting_info[i][0][\"centers\"],\n",
    "                           plotting_info[i][0][\"means\"],\n",
    "                           color = colours[i],\n",
    "                           edgecolor = \"black\", alpha = 0.3,\n",
    "                           marker = markers[i],\n",
    "                           s = 30)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    xticks = find_centres(plotting_info)\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xlabels[:len(xticks)],\n",
    "                       fontfamily = \"sans-serif\", \n",
    "                       font = \"Arial\", \n",
    "                       fontweight = \"bold\", \n",
    "                       fontsize = 12,\n",
    "                       rotation = 45,\n",
    "                       ha = \"center\")\n",
    "    ax.set_ylim(*ylims)\n",
    "    mph.update_ticks(ax, which = \"y\")\n",
    "    ax.set_ylabel(ylabel, fontfamily = \"sans-serif\",\n",
    "                  font = \"Arial\", fontweight = \"bold\",\n",
    "                  fontsize = 14)\n",
    "    if show_legend:\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  prop = mpl_fm.FontProperties(family = \"sans-serif\",\n",
    "                                               weight = \"bold\"))\n",
    "    if figfile == None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(figfile)\n",
    "    plt.close()\n",
    "    return None\n",
    "\n",
    "def replace_neg(a_list, value = float(\"nan\")):\n",
    "    \"\"\"\n",
    "    replace any value <0 with 0\n",
    "    \"\"\"\n",
    "    newlist = []\n",
    "    for item in a_list:\n",
    "        try:\n",
    "            truth = item < 0\n",
    "        except:\n",
    "            newlist.append(item)\n",
    "        else:\n",
    "            if truth:\n",
    "                newlist.append(value)\n",
    "            else:\n",
    "                newlist.append(item)\n",
    "    return newlist\n",
    "\n",
    "def safe_log2(number):\n",
    "    try:\n",
    "        log2(number)\n",
    "    except:\n",
    "        return float(\"nan\")\n",
    "    else:\n",
    "        return log2(number)\n",
    "    \n",
    "#\n",
    "#\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#\n",
    "# Variable definitions\n",
    "\n",
    "# File architechture change because we can't nromalise multiple\n",
    "# blot files at the same time (Ab switches :/)\n",
    "#data_path = \"./excel_sheets/20241128_\" # and then the rest of the file name\n",
    "\n",
    "colour_dict = {\"JE6\" : \"black\",\n",
    "               \"J132\" : \"grey\",\n",
    "               \"J133\" : \"hotpink\",\n",
    "               \"J134\" : \"aqua\",\n",
    "               \"J135\" : \"mediumpurple\",}\n",
    "\n",
    "linestyle_dict = {\"JE6\" : \"solid\",\n",
    "                  r\"J132\" : \"solid\",\n",
    "                  \"J133\" : \"dotted\",\n",
    "                  \"J134\" : \"dashed\",\n",
    "                  \"J135\" : \"dashdot\"}\n",
    "\n",
    "markers = [\"o\", \"s\", \"D\",\"^\", \"o\", \"s\", \"D\",\"^\"]\n",
    "\n",
    "experiment = [700.0, '685Ex-720Em']\n",
    "control = [800.0, '785Ex-820Em']\n",
    "\n",
    "    # Titration variables\n",
    "\n",
    "#titr_files = [f\"{data_path}titration_4g10.xlsx\",\n",
    "#              f\"{data_path}titration_erk.xlsx\"]\n",
    "\n",
    "groups = [\"JE6 0m\", \"JE6 5 m\", \"JE6 15m\",\n",
    "          \"J132 0m\", \"J132 5 m\", \"J132 15m\",\n",
    "         \"J133 0m\", \"J133 5 m\", \"J133 15m\",\n",
    "         \"J134 0m\", \"J134 5 m\", \"J134 15m\",\n",
    "         \"J135 0m\", \"J135 5 m\", \"J135 15m\",]\n",
    "\n",
    "globgroups = [\"JE6\", \"J132\", \"J133\", \"J134\", \"J135\"]\n",
    "\n",
    "\n",
    "xgroups = [\"0m\", \"5 m\", \"15m\" ]\n",
    "\n",
    "targets = [fr\"PLC$\\gamma$1\", \"Erk\"]\n",
    "\n",
    "#\n",
    "#\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#\n",
    "#  Want to normalise two files individually, then merge with \n",
    "#  correct labels\n",
    "\n",
    "    # Assume we have files, and write from there\n",
    "    \n",
    "def find_correct_signal(a_file_df,\n",
    "                        signal_values,\n",
    "                        gs_kwargs):\n",
    "    \"\"\"\n",
    "    Goal: Try to grab the signal for all the given\n",
    "          signal values, then return the ones that worked\n",
    "          returns what values were found, if none then []\n",
    "    \"\"\"\n",
    "    found = []\n",
    "    for val in signal_values:\n",
    "        found = wh.get_signal(a_file_df,\n",
    "                              val,\n",
    "                              **gs_kwargs)\n",
    "        if len(found) > 0:\n",
    "            return found\n",
    "    return found\n",
    "\n",
    "def get_all_signals(file_dfs,\n",
    "                    expr_signals = [700, \"685Ex-720Em\"],\n",
    "                    load_signals = [800, \"785Ex-820Em\"],\n",
    "                    gs_kwargs = dict(signal_column = \"Signal\",\n",
    "                                 channel_column = \"Channel\"),\n",
    "                    df_meta = [\"Group\", \"Condition\", \"Time\"]):\n",
    "    \"\"\"\n",
    "    Goal: Go through each file, grab the experimental/load\n",
    "          data, plus any specified metadata\n",
    "          return 3 lists: experimental signal, load_signal, \n",
    "                          metadata per row (only experimental)\n",
    "    \"\"\"\n",
    "    expr_out = []\n",
    "    load_out = []\n",
    "    metadata = []\n",
    "    for df in file_dfs:\n",
    "        # Temp holders for this file\n",
    "        expr_hold = find_correct_signal(df, expr_signals, gs_kwargs)\n",
    "        load_hold = find_correct_signal(df, load_signals, gs_kwargs)\n",
    "        try:\n",
    "            meta_hold = [find_correct_signal(df, expr_signals, {\"signal_column\" : metacheck,\n",
    "                                                                \"channel_column\" : \"Channel\"}) for metacheck in df_meta]\n",
    "        except:\n",
    "            meta_hold = []\n",
    "        # Add them to the returner lists\n",
    "        expr_out.append(expr_hold)\n",
    "        load_out.append(load_hold)\n",
    "        metadata.append(meta_hold)\n",
    "    # If metadata isn't empty,we want to reformat it\n",
    "    if metadata != []:\n",
    "        metadata = [gh.transpose(*g) for g in metadata]\n",
    "        metadata = [[gh.list_to_str(subg, \n",
    "                                    delimiter = \" \", \n",
    "                                    newline = False) for subg in g]\n",
    "                    for g in metadata]\n",
    "    return expr_out, load_out, metadata\n",
    "\n",
    "def merge_expr_lists(lists):\n",
    "    newlist = []\n",
    "    for i in range(len(lists[0])):\n",
    "        holder = []\n",
    "        for j in range(len(lists)):\n",
    "            holder += lists[j][i]\n",
    "        newlist.append(holder)\n",
    "    return newlist\n",
    "\n",
    "def read_norm_merge(file_dir,\n",
    "                    reps = 4,\n",
    "                    time = 3,\n",
    "                    targets = 2,\n",
    "                    treatments = 1,\n",
    "                    expr_signal = [700, \"685Ex-720Em\"],\n",
    "                    load_signal = [800, \"785Ex-820Em\"],\n",
    "                    df_meta = [],\n",
    "                    norm_inds = [0,1,2,4],\n",
    "                    gs_kwargs = dict(signal_column = \"Signal\",\n",
    "                                 channel_column = \"Channel\"),\n",
    "                    log2_trans = True,\n",
    "                    target_strs = [f\"tarrrrr{i}\" for i in range(3)],\n",
    "                   group_labels = [f\"string{i}\" for i in range(8)]):\n",
    "    \"\"\"\n",
    "    Goal: Grab the dataframe files, use the Western Helpers\n",
    "          stuff to do some of the management/normalisation\n",
    "          and finally merge the files\n",
    "    \"\"\"\n",
    "    # First, get a list of all the files. We assume this whole\n",
    "    # directory is merging into one final file\n",
    "    files = glob.glob(f\"{file_dir}/*\")\n",
    "    print(files)\n",
    "    files = [pd.read_excel(f) for f in files]\n",
    "    \n",
    "    expr_sigs, load_sigs, metadata = get_all_signals(files,\n",
    "                                                     expr_signals = expr_signal,\n",
    "                                                     load_signals = load_signal,\n",
    "                                                     gs_kwargs = gs_kwargs,\n",
    "                                                     df_meta = df_meta)\n",
    "    expr_sigs = [[blot[reps*time*treatments*i:reps*time*treatments*(i+1)] for i in range(targets)] \n",
    "                 for blot in expr_sigs]\n",
    "    expr_sigs = merge_expr_lists(expr_sigs)\n",
    "    load_sigs = [[blot[reps*time*treatments*i:reps*time*treatments*(i+1)] for i in range(targets)] \n",
    "                 for blot in load_sigs]\n",
    "    load_sigs = merge_expr_lists(load_sigs)\n",
    "    # Alright, now that we have all the information we need, we\n",
    "    # can start croonchin noombres\n",
    "    corrected_sigs = [wh.licor_correction(expr_sigs[i],\n",
    "                                          load_sigs[i]) for i in range(len(expr_sigs))]\n",
    "    norm_means = [sh.mean([corrected_sigs[i][j] for j in norm_inds]) for i in range(len(corrected_sigs))]\n",
    "    norm_sigs = [[log2(item/norm_means[i]) for item in corrected_sigs[i]]\n",
    "                 for i in range(len(corrected_sigs))]\n",
    "    grouped_sigs = [[[group_labels[i], target[reps*i:reps*(i+1)]] for i in range(len(group_labels))]\n",
    "                   for target in norm_sigs]\n",
    "    return {target_strs[i] : grouped_sigs[i] for i in range(len(target_strs))}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./cars/01_je6_proteomics.xls', './cars/02_j132_proteomics.xls', './cars/03_j133_proteomics.xls', './cars/04_j134_proteomics.xls', './cars/05_j135_proteomics.xls']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PLC$\\\\gamma$1': [['JE6 0m',\n",
       "   [-0.02528661761005492,\n",
       "    -0.3306681970281252,\n",
       "    0.16873452292733895,\n",
       "    -0.0187681029187778]],\n",
       "  ['JE6 5 m',\n",
       "   [0.1350547263523936,\n",
       "    0.28397754072270015,\n",
       "    0.09736239217815448,\n",
       "    0.37043976474229096]],\n",
       "  ['JE6 15m',\n",
       "   [0.4785230200365176,\n",
       "    -0.3123974023621218,\n",
       "    0.5099650583196198,\n",
       "    0.5518926763294206]],\n",
       "  ['J132 0m',\n",
       "   [0.24471658750558542,\n",
       "    0.502398125101867,\n",
       "    0.21595367991125672,\n",
       "    0.2563304059641972]],\n",
       "  ['J132 5 m',\n",
       "   [2.5789277632735117,\n",
       "    2.710935518979545,\n",
       "    2.7052974106289844,\n",
       "    2.527596744033124]],\n",
       "  ['J132 15m',\n",
       "   [2.1908925774556653,\n",
       "    2.16965032352206,\n",
       "    1.8617346220930417,\n",
       "    1.9407685818742424]],\n",
       "  ['J133 0m',\n",
       "   [-0.23264655446140198,\n",
       "    -0.1671548346706228,\n",
       "    -0.19163313153137224,\n",
       "    -0.0666754393548077]],\n",
       "  ['J133 5 m',\n",
       "   [1.2411671251688994,\n",
       "    1.1034943209790504,\n",
       "    1.143002801254938,\n",
       "    1.1256811502807325]],\n",
       "  ['J133 15m',\n",
       "   [0.3642584103669805,\n",
       "    0.5704882044843755,\n",
       "    0.5779198164308006,\n",
       "    0.3973518488185892]],\n",
       "  ['J134 0m',\n",
       "   [-0.18143313441756662,\n",
       "    -0.17593508423395748,\n",
       "    -0.2971160142408117,\n",
       "    -0.2616152994170166]],\n",
       "  ['J134 5 m',\n",
       "   [1.440028690054483,\n",
       "    1.4339239168927524,\n",
       "    1.5508342884436241,\n",
       "    1.4936624184203573]],\n",
       "  ['J134 15m',\n",
       "   [0.8437846148254332,\n",
       "    0.5940410205219766,\n",
       "    0.8573942671452827,\n",
       "    0.6858858134012399]],\n",
       "  ['J135 0m',\n",
       "   [-1.0956436897428816,\n",
       "    -1.0175363285209145,\n",
       "    -0.9725950144754181,\n",
       "    -1.0481300418706423]],\n",
       "  ['J135 5 m',\n",
       "   [1.0135238187949995,\n",
       "    0.9214659811366255,\n",
       "    0.9901605435621698,\n",
       "    0.9890544919373359]],\n",
       "  ['J135 15m',\n",
       "   [0.14235161490325685,\n",
       "    0.21926130852214198,\n",
       "    0.07415034924249096,\n",
       "    0.07997633465062771]]],\n",
       " 'Erk': [['JE6 0m',\n",
       "   [0.07148578696977016,\n",
       "    -0.10969436456462917,\n",
       "    0.44314701011259044,\n",
       "    -0.0341177080707924]],\n",
       "  ['JE6 5 m',\n",
       "   [-0.593244501077413,\n",
       "    -0.5320032896670257,\n",
       "    -0.6628026170869061,\n",
       "    -0.5604811585553141]],\n",
       "  ['JE6 15m',\n",
       "   [1.31385620645022,\n",
       "    1.3178459820720352,\n",
       "    0.9833625629977737,\n",
       "    1.162622517679818]],\n",
       "  ['J132 0m',\n",
       "   [-0.053888733652768014,\n",
       "    0.12487481046723255,\n",
       "    0.24264426926938942,\n",
       "    0.6341201495160744]],\n",
       "  ['J132 5 m',\n",
       "   [2.501345397761507,\n",
       "    2.5535281484623673,\n",
       "    2.593532319234132,\n",
       "    2.6841489318278495]],\n",
       "  ['J132 15m',\n",
       "   [2.849590893026741,\n",
       "    2.9259211706265016,\n",
       "    2.6543928817146267,\n",
       "    2.6061668713881745]],\n",
       "  ['J133 0m',\n",
       "   [-0.23750239052961342,\n",
       "    0.018336260894927865,\n",
       "    -0.11836473073754293,\n",
       "    -0.24569932560765742]],\n",
       "  ['J133 5 m',\n",
       "   [1.684898912221126,\n",
       "    1.668205029048679,\n",
       "    1.5656519221891367,\n",
       "    1.540419931603276]],\n",
       "  ['J133 15m',\n",
       "   [1.7158805367653023,\n",
       "    1.724523812815505,\n",
       "    1.5957933000540088,\n",
       "    1.4457437176502625]],\n",
       "  ['J134 0m',\n",
       "   [-0.9737753403428385,\n",
       "    -1.0709490479240562,\n",
       "    -1.0152234077306432,\n",
       "    -1.000762397510013]],\n",
       "  ['J134 5 m',\n",
       "   [1.539279119723985,\n",
       "    1.6393518591744345,\n",
       "    1.6199123297785585,\n",
       "    1.5765807967102214]],\n",
       "  ['J134 15m',\n",
       "   [1.7689123355198708,\n",
       "    1.7335395273279202,\n",
       "    1.9271655245140347,\n",
       "    1.6300583408471243]],\n",
       "  ['J135 0m',\n",
       "   [-2.0027402302367987,\n",
       "    -1.6825653651606298,\n",
       "    -1.6177219313504085,\n",
       "    -1.622782300781873]],\n",
       "  ['J135 5 m',\n",
       "   [1.828955698542821,\n",
       "    1.9225023277313888,\n",
       "    1.9291699932833575,\n",
       "    2.0036259399033884]],\n",
       "  ['J135 15m',\n",
       "   [1.7649748411293948,\n",
       "    1.6970687751733953,\n",
       "    1.755148924926927,\n",
       "    1.6590893869944436]]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_norm_merge(\"./cars\", group_labels = groups, target_strs = targets)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./cars/01_je6_proteomics.xls', './cars/02_j132_proteomics.xls', './cars/03_j133_proteomics.xls', './cars/04_j134_proteomics.xls', './cars/05_j135_proteomics.xls']\n"
     ]
    }
   ],
   "source": [
    "stats = [\"./stats/cars_plcg1\",\n",
    "         \"./stats/cars_erk\"]\n",
    "figs = [\"./figs/cars_plcg1.pdf\",\n",
    "            \"./figs/cars_erk.pdf\"]\n",
    "\n",
    "ylims = [[-1.5,3], [-2,3], [-5,10]]\n",
    "\n",
    "data = read_norm_merge(\"./cars\", group_labels = groups, target_strs = targets)\n",
    "\n",
    "counter = 0\n",
    "for key, value in data.items():\n",
    "    ignore = _logical_ignore_comps([value],\n",
    "                                   group_strs = globgroups,\n",
    "                                   xgroup_strs = xgroups)\n",
    "    \n",
    "    line_plot([value[3*i:3*(i+1)] for i in range(5)], \n",
    "              ylims = ylims[counter],\n",
    "              colours = [colour_dict[\"JE6\"],\n",
    "                         colour_dict[\"J132\"],\n",
    "                         colour_dict[\"J133\"],\n",
    "                         colour_dict[\"J134\"],\n",
    "                         colour_dict[\"J135\"]],\n",
    "              markers = markers,\n",
    "              linestyles = [linestyle_dict[\"JE6\"],\n",
    "                         linestyle_dict[\"J132\"],\n",
    "                         linestyle_dict[\"J133\"],\n",
    "                         linestyle_dict[\"J134\"],\n",
    "                            linestyle_dict[\"J135\"]],\n",
    "              xlabels = xgroups,\n",
    "              show_points = False,\n",
    "              show_legend = True,\n",
    "              group_labs = globgroups,\n",
    "             ignore_comps = ignore,\n",
    "              statsfile = stats[counter],\n",
    "              figfile = figs[counter],\n",
    "              comp_type = \"HolmSidak\",\n",
    "              ylabel = r\"$\\log_{2}$ Fold Change\")\n",
    "    \n",
    "    counter += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh.western_quant(\"./ot1/ot1_erk.xlsx\", \n",
    "                 exp_channel = \"685Ex-720Em\",\n",
    "                 control_channel = \"785Ex-820Em\",\n",
    "                 bins = 3, \n",
    "                 labels = [\"0m\", \"5m\", \"15m\"],\n",
    "                 group_sizes = [5,5,5],\n",
    "                 filename = \"./figs/ot1_erk.pdf\",\n",
    "                 title = \"ot1 erk\",\n",
    "                 ylabel = \"Corrected pErk Signal (p.d.u.)\",\n",
    "                 colours = mph.colours[\"browns\"][:3],\n",
    "                 foldchange_axis = True,\n",
    "                 foldchange_group = \"0m\",)\n",
    "\n",
    "wh.western_quant(\"./ot1/jot1_plc.xls\", \n",
    "                 exp_channel = \"685Ex-720Em\",\n",
    "                 control_channel = \"785Ex-820Em\",\n",
    "                 bins = 3, \n",
    "                 labels = [\"0m\", \"5m\", \"15m\"],\n",
    "                 group_sizes = [5,5,5],\n",
    "                 filename = \"./figs/ot1_plc.pdf\",\n",
    "                 title = \"ot1 plc\",\n",
    "                 ylabel = \"Corrected pPLCg1 Signal (p.d.u.)\",\n",
    "                 colours = mph.colours[\"browns\"][:3],\n",
    "                 foldchange_axis = True,\n",
    "                 foldchange_group = \"0m\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function western_quant in module helpers.western_helpers:\n",
      "\n",
      "western_quant(file1, file2=None, exp_channel=800, control_channel=700, bins=4, labels=[], group_sizes=[], filename='dotplot.pdf', title='Dotplot', ylabel='Abundance', colours=[], errorbar='sem', foldchange_axis=False, foldchange_group=None, test='Holm-Sidak', perform_stats=True, stats_outfile_type='xlsx', alpha=0.05, sig_dict={0.05: '$*$', 0.01: '$*$$*$', 0.001: '$*$$*$$*$'}, p_or_q='p')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(wh.western_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blues': ['steelblue',\n",
       "  'cyan',\n",
       "  'blue',\n",
       "  'darkblue',\n",
       "  'dodgerblue',\n",
       "  'lightblue',\n",
       "  'deepskyblue'],\n",
       " 'pinks': ['mediumvioletred',\n",
       "  'darkmagenta',\n",
       "  'deeppink',\n",
       "  'violet',\n",
       "  'magenta',\n",
       "  'pink',\n",
       "  'lavenderblush'],\n",
       " 'reds': ['darkred',\n",
       "  'firebrick',\n",
       "  'indianred',\n",
       "  'red',\n",
       "  'tomato',\n",
       "  'salmon',\n",
       "  'lightcoral',\n",
       "  'darksalmon',\n",
       "  'mistyrose'],\n",
       " 'purples': ['indigo',\n",
       "  'mediumpurple',\n",
       "  'purple',\n",
       "  'darkviolet',\n",
       "  'mediumorchid',\n",
       "  'plum',\n",
       "  'thistle'],\n",
       " 'greens': ['darkolivegreen',\n",
       "  'olivedrab',\n",
       "  'green',\n",
       "  'limegreen',\n",
       "  'chartreuse',\n",
       "  'springgreen',\n",
       "  'lawngreen'],\n",
       " 'oranges': ['darkorange',\n",
       "  'orange',\n",
       "  'goldenrod',\n",
       "  'gold',\n",
       "  'yellow',\n",
       "  'khaki',\n",
       "  'lightyellow'],\n",
       " 'browns': ['brown',\n",
       "  'saddlebrown',\n",
       "  'sienna',\n",
       "  'chocolate',\n",
       "  'peru',\n",
       "  'sandybrown',\n",
       "  'burlywood'],\n",
       " 'monos': ['black',\n",
       "  'dimgrey',\n",
       "  'grey',\n",
       "  'darkgrey',\n",
       "  'silver',\n",
       "  'lightgrey',\n",
       "  'gainsboro'],\n",
       " 'cc': ['darkturquoise', 'cyan', 'thistle', 'fuchsia', 'violet'],\n",
       " 'default': ['blue', 'red', 'green', 'purple', 'pink'],\n",
       " 'all': ['darkblue',\n",
       "  'steelblue',\n",
       "  'blue',\n",
       "  'dodgerblue',\n",
       "  'deepskyblue',\n",
       "  'aqua',\n",
       "  'lightblue',\n",
       "  'cornflowerblue',\n",
       "  'darkmagenta',\n",
       "  'mediumvioletred',\n",
       "  'deeppink',\n",
       "  'violet',\n",
       "  'magenta',\n",
       "  'pink',\n",
       "  'lavenderblush',\n",
       "  'darkred',\n",
       "  'firebrick',\n",
       "  'indianred',\n",
       "  'red',\n",
       "  'tomato',\n",
       "  'salmon',\n",
       "  'lightcoral',\n",
       "  'darksalmon',\n",
       "  'mistyrose',\n",
       "  'indigo',\n",
       "  'rebeccapurple',\n",
       "  'mediumpurple',\n",
       "  'purple',\n",
       "  'darkviolet',\n",
       "  'mediumorchid',\n",
       "  'plum',\n",
       "  'thistle',\n",
       "  'darkolivegreen',\n",
       "  'olivedrab',\n",
       "  'green',\n",
       "  'forestgreen',\n",
       "  'limegreen',\n",
       "  'springgreen',\n",
       "  'lawngreen',\n",
       "  'palegreen',\n",
       "  'darkorange',\n",
       "  'orange',\n",
       "  'goldenrod',\n",
       "  'gold',\n",
       "  'yellow',\n",
       "  'khaki',\n",
       "  'lightyellow',\n",
       "  'brown',\n",
       "  'saddlebrown',\n",
       "  'sienna',\n",
       "  'chocolate',\n",
       "  'peru',\n",
       "  'sandybrown',\n",
       "  'burlywood',\n",
       "  'wheat',\n",
       "  'black',\n",
       "  'dimgrey',\n",
       "  'grey',\n",
       "  'darkgrey',\n",
       "  'silver',\n",
       "  'lightgrey',\n",
       "  'gainsboro',\n",
       "  'white']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mph.colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".whores",
   "language": "python",
   "name": ".whores"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
