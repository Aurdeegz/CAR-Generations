{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importables\n",
    "\n",
    "from helpers import general_helpers as gh\n",
    "from helpers import stats_helpers as sh\n",
    "from helpers import mpl_plotting_helpers as mph\n",
    "from helpers import western_helpers as wh\n",
    "from helpers.mph_modules.dotplots import get_data_info, add_errorbar\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from math import log2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as mpl_fm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#\n",
    "# Making line plots and doing the statistics\n",
    "#  #  #  # Add to mpl_plotting_helpers at some point\n",
    "\n",
    "def _logical_ignore_comps(labelled_line_groups,\n",
    "                          group_strs,\n",
    "                          xgroup_strs):\n",
    "    \"\"\"\n",
    "    Only want to compare along a line group (e.g. timecourse) or\n",
    "    down an x-column (e.g. JE6 DMSO 0m vs JE6 U0126 0m), but not\n",
    "    all the random other comparisons because statistically they're\n",
    "    kind of useless\n",
    "    \n",
    "    So this function will find all of the pairs that are useless\n",
    "    \"\"\"\n",
    "    groups_unpacked = []\n",
    "    for group in labelled_line_groups:\n",
    "        groups_unpacked += group\n",
    "    # This will hold the ignored pairs\n",
    "    ignore_me_senpai = []\n",
    "    # First, get all pairs\n",
    "    paired = gh.make_pairs(groups_unpacked,\n",
    "                           dupes = False,\n",
    "                           reverse = False)\n",
    "    # Then iterate over and check the labels\n",
    "    for p in paired:\n",
    "        gs_check = 0\n",
    "        xs_check = 0\n",
    "        # Check all the group strings\n",
    "        for gs in group_strs:\n",
    "            if gs_check == 1:\n",
    "                pass\n",
    "            elif gs in p[0][0] and gs in p[1][0]:\n",
    "                gs_check = 1\n",
    "        # Check all the xgroup strings\n",
    "        for xs in xgroup_strs:\n",
    "            if xs_check == 1:\n",
    "                pass\n",
    "            elif xs in p[0][0] and xs in p[1][0]:\n",
    "                xs_check = 1\n",
    "        # If there isn't a match, in either, ignore\n",
    "        if gs_check == 0 and xs_check == 0:\n",
    "            ignore_me_senpai.append(p)\n",
    "    # Return the ignored pairs at the end\n",
    "    return ignore_me_senpai\n",
    "\n",
    "def perform_line_statistics(labelled_line_groups,\n",
    "                            ignore_comps,\n",
    "                            comp_type,\n",
    "                            statsfile):\n",
    "    \"\"\"\n",
    "    labelled_line_groups -> data with labels\n",
    "                            list of lists of [label, [d1,d2,...,dn]]\n",
    "    ignore_comps -> list of pairs (\"group 1\", \"group 2\") to not be\n",
    "                    compared\n",
    "    comp_type -> statistics to use, currently only\n",
    "                 [\"HolmSidak\", \"TukeyHSD\"] are supported\n",
    "                 (both do an ANOVA first by default)\n",
    "    statsfile -> a string to the output path and filename\n",
    "                 for the statistics file output\n",
    "    #####\n",
    "    Returns None, just dumps the statsfile\n",
    "    \"\"\"\n",
    "    assert comp_type in [\"HolmSidak\", \"TukeyHSD\"], f\"Invalid comparison type: {comp_type}\"\n",
    "    groups_unpacked = []\n",
    "    for group in labelled_line_groups:\n",
    "        groups_unpacked += group\n",
    "    if comp_type == \"HolmSidak\":\n",
    "        comparison = sh.HolmSidak(*groups_unpacked,\n",
    "                                  labels = True,\n",
    "                                  override = True,\n",
    "                                  alpha = 0.05,\n",
    "                                  no_comp = ignore_comps)\n",
    "    elif comp_type == \"TukeyHSD\":\n",
    "        comparison = sh.TukeyHSD(*groups_unpacked,\n",
    "                                  labels = True,\n",
    "                                  override = True,\n",
    "                                  alpha = 0.05,\n",
    "                                  no_comp = ignore_comps)\n",
    "    comparison.write_output(filename = statsfile,\n",
    "                            file_type = \"csv\")\n",
    "    return None\n",
    "\n",
    "def find_centres(plotting_info):\n",
    "    \"\"\"\n",
    "    plotting_info -> output from get_data_info, a list of\n",
    "                     data info and the raw data\n",
    "                     \n",
    "    goal: grab the centres for xticks\n",
    "    \"\"\"\n",
    "    centres = []\n",
    "    for group in plotting_info:\n",
    "        if len(centres) <= len(group[0][\"centers\"]):\n",
    "            centres = group[0][\"centers\"]\n",
    "    return centres\n",
    "\n",
    "def line_plot(labelled_line_groups,\n",
    "              show_points = False,\n",
    "              show_legend = False,\n",
    "              colours = [\"grey\" for _ in range(20)],\n",
    "              group_labs = [f\"Thing {i}\" for i in range(20)],\n",
    "              markers = [\"s\" for _ in range(20)],\n",
    "              linestyles = [\"solid\" for _ in range(20)],\n",
    "              xlabels = [f\"Time {i}\" for i in range(20)],\n",
    "              ylabel = [\"Fold change\"],\n",
    "              ylims = None,\n",
    "              ignore_comps = [],\n",
    "              statsfile = None,\n",
    "              comp_type = \"HolmSidak\",\n",
    "              figfile = None):\n",
    "    \"\"\"\n",
    "    labelled_line_groups -> list of lists, where each sublist contains labelled groups\n",
    "    \"\"\"\n",
    "    # First, get some basic plotting information\n",
    "    plotting_info = [get_data_info(line) for line in labelled_line_groups]\n",
    "    # Then manage the statistics\n",
    "    if statsfile != None:\n",
    "        perform_line_statistics(labelled_line_groups, \n",
    "                                ignore_comps, \n",
    "                                comp_type, \n",
    "                                statsfile)\n",
    "    # Begin plotting c::\n",
    "    if ylims == None:\n",
    "        ylims = floor(min([item for item in gh.unpack_list(labelled_line_groups) if type(item) in [int, float]])), ceil(max([item for item in gh.unpack_list(labelled_line_groups) if type(item) in [int, float]]))\n",
    "    # \n",
    "    fig, ax = plt.subplots(figsize = (6,6))\n",
    "    # \n",
    "    for i in range(len(labelled_line_groups)):\n",
    "        #\n",
    "        ax.plot(plotting_info[i][0][\"centers\"],\n",
    "                plotting_info[i][0][\"means\"],\n",
    "                color = colours[i],\n",
    "                label = group_labs[i],\n",
    "                linestyle = linestyles[i])\n",
    "        #\n",
    "        for j in range(len(labelled_line_groups[i])):\n",
    "            add_errorbar(ax, \n",
    "                         plotting_info[i][0][\"centers\"][j],\n",
    "                         plotting_info[i][0][\"means\"][j],\n",
    "                         plotting_info[i][0][\"sems\"][j],\n",
    "                         color = colours[i])\n",
    "            if show_points:\n",
    "            #\n",
    "                ax.scatter(plotting_info[i][0][\"xs\"][j],\n",
    "                           plotting_info[i][1][j][1],\n",
    "                           color = colours[i],\n",
    "                           edgecolor = \"black\", alpha = 0.3,\n",
    "                           marker = markers[i],\n",
    "                           s = 10)\n",
    "            else:\n",
    "            #\n",
    "                ax.scatter(plotting_info[i][0][\"centers\"],\n",
    "                           plotting_info[i][0][\"means\"],\n",
    "                           color = colours[i],\n",
    "                           edgecolor = \"black\", alpha = 0.3,\n",
    "                           marker = markers[i],\n",
    "                           s = 30)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    xticks = find_centres(plotting_info)\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xlabels[:len(xticks)],\n",
    "                       fontfamily = \"sans-serif\", \n",
    "                       font = \"Arial\", \n",
    "                       fontweight = \"bold\", \n",
    "                       fontsize = 12,\n",
    "                       rotation = 45,\n",
    "                       ha = \"center\")\n",
    "    ax.set_ylim(*ylims)\n",
    "    mph.update_ticks(ax, which = \"y\")\n",
    "    ax.set_ylabel(ylabel, fontfamily = \"sans-serif\",\n",
    "                  font = \"Arial\", fontweight = \"bold\",\n",
    "                  fontsize = 14)\n",
    "    if show_legend:\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "                  prop = mpl_fm.FontProperties(family = \"sans-serif\",\n",
    "                                               weight = \"bold\"))\n",
    "    if figfile == None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(figfile)\n",
    "    plt.close()\n",
    "    return None\n",
    "\n",
    "def replace_neg(a_list, value = float(\"nan\")):\n",
    "    \"\"\"\n",
    "    replace any value <0 with 0\n",
    "    \"\"\"\n",
    "    newlist = []\n",
    "    for item in a_list:\n",
    "        try:\n",
    "            truth = item < 0\n",
    "        except:\n",
    "            newlist.append(item)\n",
    "        else:\n",
    "            if truth:\n",
    "                newlist.append(value)\n",
    "            else:\n",
    "                newlist.append(item)\n",
    "    return newlist\n",
    "\n",
    "def safe_log2(number):\n",
    "    try:\n",
    "        log2(number)\n",
    "    except:\n",
    "        return float(\"nan\")\n",
    "    else:\n",
    "        return log2(number)\n",
    "    \n",
    "#\n",
    "#\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#\n",
    "# Variable definitions\n",
    "\n",
    "# File architechture change because we can't nromalise multiple\n",
    "# blot files at the same time (Ab switches :/)\n",
    "#data_path = \"./excel_sheets/20241128_\" # and then the rest of the file name\n",
    "\n",
    "colour_dict = {\"DMSO\" : \"grey\",\n",
    "               \"N22-IN-1\" : \"tab:orange\",\n",
    "               \"PP1\" : \"tab:orange\",\n",
    "               \"TPI-1\" : \"tab:red\",\n",
    "               \"Soq\" : \"tab:red\",\n",
    "               \"PV\" : \"saddlebrown\",\n",
    "               \"U0126\" : \"saddlebrown\",}\n",
    "\n",
    "linestyle_dict = {\"DMSO\" : \"solid\",\n",
    "                  r\"N22-IN-1\" : \"dashdot\",\n",
    "                  \"PP1\" : \"dashdot\",\n",
    "                  \"TPI-1\" : \"dashed\",\n",
    "                  \"Soq\" : \"dashed\",\n",
    "                  \"PV\" : \"dotted\",\n",
    "                  \"U0126\" : \"dotted\",}\n",
    "\n",
    "markers = [\"o\", \"s\", \"D\",\"^\", \"o\", \"s\", \"D\",\"^\"]\n",
    "\n",
    "experiment = [700.0, '685Ex-720Em']\n",
    "control = [800.0, '785Ex-820Em']\n",
    "\n",
    "    # Titration variables\n",
    "\n",
    "#titr_files = [f\"{data_path}titration_4g10.xlsx\",\n",
    "#              f\"{data_path}titration_erk.xlsx\"]\n",
    "\n",
    "ppase_groups = [\"DMSO 0m\", \"DMSO 5m\",\n",
    "                \"PV 0m\", \"PV 5m\",\n",
    "                \"TPI-1 0m\", \"TPI-1 5m\",\n",
    "                \"N22-IN-1 0m\", \"N22-IN-1 5m\",\n",
    "                ]\n",
    "kin_groups = [\"DMSO 0m\", \"DMSO 5m\",\n",
    "              \"PP1 0m\", \"PP1 5m\",\n",
    "              \"Soq 0m\", \"Soq 5m\",\n",
    "              \"U0126 0m\", \"U0126 5m\"]\n",
    "\n",
    "ppase_globgroups = [\"DMSO\", \"PV\", \"TPI-1\", \"N22-IN-1\"]\n",
    "kin_globgroups = [\"DMSO\", \"PP1\", \"Soq\", \"U0126\"]\n",
    "\n",
    "\n",
    "xgroups = [\"0m\", \"5m\" ]\n",
    "\n",
    "targets = [fr\"PLC$\\gamma$1\", \"Lck\", \"Erk\"]\n",
    "\n",
    "#\n",
    "#\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#\n",
    "#  Want to normalise two files individually, then merge with \n",
    "#  correct labels\n",
    "\n",
    "    # Assume we have files, and write from there\n",
    "    \n",
    "def find_correct_signal(a_file_df,\n",
    "                        signal_values,\n",
    "                        gs_kwargs):\n",
    "    \"\"\"\n",
    "    Goal: Try to grab the signal for all the given\n",
    "          signal values, then return the ones that worked\n",
    "          returns what values were found, if none then []\n",
    "    \"\"\"\n",
    "    found = []\n",
    "    for val in signal_values:\n",
    "        found = wh.get_signal(a_file_df,\n",
    "                              val,\n",
    "                              **gs_kwargs)\n",
    "        if len(found) > 0:\n",
    "            return found\n",
    "    return found\n",
    "\n",
    "def get_all_signals(file_dfs,\n",
    "                    expr_signals = [700, \"685Ex-720Em\"],\n",
    "                    load_signals = [800, \"785Ex-820Em\"],\n",
    "                    gs_kwargs = dict(signal_column = \"Signal\",\n",
    "                                 channel_column = \"Channel\"),\n",
    "                    df_meta = [\"Group\", \"Condition\", \"Time\"]):\n",
    "    \"\"\"\n",
    "    Goal: Go through each file, grab the experimental/load\n",
    "          data, plus any specified metadata\n",
    "          return 3 lists: experimental signal, load_signal, \n",
    "                          metadata per row (only experimental)\n",
    "    \"\"\"\n",
    "    expr_out = []\n",
    "    load_out = []\n",
    "    metadata = []\n",
    "    for df in file_dfs:\n",
    "        # Temp holders for this file\n",
    "        expr_hold = find_correct_signal(df, expr_signals, gs_kwargs)\n",
    "        load_hold = find_correct_signal(df, load_signals, gs_kwargs)\n",
    "        try:\n",
    "            meta_hold = [find_correct_signal(df, expr_signals, {\"signal_column\" : metacheck,\n",
    "                                                                \"channel_column\" : \"Channel\"}) for metacheck in df_meta]\n",
    "        except:\n",
    "            meta_hold = []\n",
    "        # Add them to the returner lists\n",
    "        expr_out.append(expr_hold)\n",
    "        load_out.append(load_hold)\n",
    "        metadata.append(meta_hold)\n",
    "    # If metadata isn't empty,we want to reformat it\n",
    "    if metadata != []:\n",
    "        metadata = [gh.transpose(*g) for g in metadata]\n",
    "        metadata = [[gh.list_to_str(subg, \n",
    "                                    delimiter = \" \", \n",
    "                                    newline = False) for subg in g]\n",
    "                    for g in metadata]\n",
    "    return expr_out, load_out, metadata\n",
    "\n",
    "def read_norm_merge(file_dir,\n",
    "                    reps = 3,\n",
    "                    time = 2,\n",
    "                    targets = 3,\n",
    "                    treatments = 2,\n",
    "                    expr_signal = [700, \"685Ex-720Em\"],\n",
    "                    load_signal = [800, \"785Ex-820Em\"],\n",
    "                    df_meta = [],\n",
    "                    norm_inds = [0,1,2],\n",
    "                    gs_kwargs = dict(signal_column = \"Signal\",\n",
    "                                 channel_column = \"Channel\"),\n",
    "                    log2_trans = True,\n",
    "                    target_strs = [f\"tarrrrr{i}\" for i in range(3)],\n",
    "                   group_labels = [f\"string{i}\" for i in range(8)]):\n",
    "    \"\"\"\n",
    "    Goal: Grab the dataframe files, use the Western Helpers\n",
    "          stuff to do some of the management/normalisation\n",
    "          and finally merge the files\n",
    "    \"\"\"\n",
    "    # First, get a list of all the files. We assume this whole\n",
    "    # directory is merging into one final file\n",
    "    files = glob.glob(f\"{file_dir}/*\")\n",
    "    files = [pd.read_excel(f) for f in files]\n",
    "    \n",
    "    expr_sigs, load_sigs, metadata = get_all_signals(files,\n",
    "                                                     expr_signals = expr_signal,\n",
    "                                                     load_signals = load_signal,\n",
    "                                                     gs_kwargs = gs_kwargs,\n",
    "                                                     df_meta = df_meta)\n",
    "    expr_sigs = [[blot[reps*time*treatments*i:reps*time*treatments*(i+1)] for i in range(targets)] \n",
    "                 for blot in expr_sigs]\n",
    "    expr_sigs = [expr_sigs[0][i] + expr_sigs[1][i] for i in range(len(expr_sigs[0]))]\n",
    "    load_sigs = [[blot[reps*time*treatments*i:reps*time*treatments*(i+1)] for i in range(targets)] \n",
    "                 for blot in load_sigs]\n",
    "    load_sigs = [load_sigs[0][i] + load_sigs[1][i] for i in range(len(load_sigs[0]))]\n",
    "    # Alright, now that we have all the information we need, we\n",
    "    # can start croonchin noombres\n",
    "    corrected_sigs = [wh.licor_correction(expr_sigs[i],\n",
    "                                          load_sigs[i]) for i in range(len(expr_sigs))]\n",
    "    norm_means = [sh.mean([corrected_sigs[i][j] for j in norm_inds]) for i in range(len(corrected_sigs))]\n",
    "    norm_sigs = [[log2(item/norm_means[i]) for item in corrected_sigs[i]]\n",
    "                 for i in range(len(corrected_sigs))]\n",
    "    grouped_sigs = [[[group_labels[i], target[reps*i:reps*(i+1)]] for i in range(len(group_labels))]\n",
    "                   for target in norm_sigs]\n",
    "    return {target_strs[i] : grouped_sigs[i] for i in range(len(target_strs))}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "kin_stats = [\"./stats/kinase_plcg1\",\n",
    "         \"./stats/kinase_lck\",\n",
    "         \"./stats/kinase_erk\"]\n",
    "kin_figs = [\"./figs/kinase_plcg1.pdf\",\n",
    "            \"./figs/kinase_lck.pdf\",\n",
    "            \"./figs/kinase_erk.pdf\"]\n",
    "\n",
    "kin_ylims = [[-1,4], [-2,3], [-3,6]]\n",
    "\n",
    "kin_data = read_norm_merge(\"./kinase\", group_labels = kin_groups, target_strs = targets)\n",
    "\n",
    "counter = 0\n",
    "for key, value in kin_data.items():\n",
    "    ignore = _logical_ignore_comps([value],\n",
    "                                   group_strs = kin_globgroups,\n",
    "                                   xgroup_strs = xgroups)\n",
    "    \n",
    "    line_plot([value[2*i:2*(i+1)] for i in range(4)], \n",
    "              ylims = kin_ylims[counter],\n",
    "              colours = [colour_dict[\"DMSO\"],\n",
    "                         colour_dict[\"PP1\"],\n",
    "                         colour_dict[\"Soq\"],\n",
    "                         colour_dict[\"U0126\"]],\n",
    "              markers = markers,\n",
    "              linestyles = [linestyle_dict[\"DMSO\"],\n",
    "                         linestyle_dict[\"PP1\"],\n",
    "                         linestyle_dict[\"Soq\"],\n",
    "                         linestyle_dict[\"U0126\"]],\n",
    "              xlabels = xgroups,\n",
    "              show_points = False,\n",
    "              show_legend = True,\n",
    "              group_labs = kin_globgroups,\n",
    "             ignore_comps = ignore,\n",
    "              statsfile = kin_stats[counter],\n",
    "              figfile = kin_figs[counter],\n",
    "              comp_type = \"HolmSidak\",\n",
    "              ylabel = r\"$\\log_{2}$ Fold Change\")\n",
    "    \n",
    "    counter += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppase_stats = [\"./stats/ppase_plcg1\",\n",
    "         \"./stats/ppase_lck\",\n",
    "         \"./stats/ppase_erk\"]\n",
    "ppase_figs = [\"./figs/ppase_plcg1.pdf\",\n",
    "            \"./figs/ppase_lck.pdf\",\n",
    "            \"./figs/ppase_erk.pdf\"]\n",
    "\n",
    "ppase_ylims = [[-1,6], [-1,4], [-2,7]]\n",
    "\n",
    "ppase_data = read_norm_merge(\"./phosphatase\", group_labels = ppase_groups, target_strs = targets)\n",
    "\n",
    "counter = 0\n",
    "for key, value in ppase_data.items():\n",
    "    ignore = _logical_ignore_comps([value],\n",
    "                                   group_strs = ppase_globgroups,\n",
    "                                   xgroup_strs = xgroups)\n",
    "    \n",
    "    line_plot([value[2*i:2*(i+1)] for i in range(4)], \n",
    "              ylims = ppase_ylims[counter],\n",
    "              colours = [colour_dict[\"DMSO\"],\n",
    "                         colour_dict[\"PV\"],\n",
    "                         colour_dict[\"TPI-1\"],\n",
    "                         colour_dict[\"N22-IN-1\"]],\n",
    "              markers = markers,\n",
    "              linestyles = [linestyle_dict[\"DMSO\"],\n",
    "                         linestyle_dict[\"PV\"],\n",
    "                         linestyle_dict[\"TPI-1\"],\n",
    "                         linestyle_dict[\"N22-IN-1\"]],\n",
    "              xlabels = xgroups,\n",
    "              show_points = False,\n",
    "              show_legend = True,\n",
    "              group_labs = ppase_globgroups,\n",
    "             ignore_comps = ignore,\n",
    "              statsfile = ppase_stats[counter],\n",
    "              figfile = ppase_figs[counter],\n",
    "              comp_type = \"HolmSidak\",\n",
    "              ylabel = r\"$\\log_{2}$ Fold Change\")\n",
    "    \n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLC$\\\\gamma$1': [['DMSO 0m',\n",
       "   [0.08515049017990967, 0.04385522063334452, -0.13870084773727953]],\n",
       "  ['DMSO 5m', [2.7977855395979088, 2.4045176164313986, 2.9616571357959187]],\n",
       "  ['PV 0m', [0.9727156042559899, 0.9314139202850424, 0.9360046963943555]],\n",
       "  ['PV 5m', [5.663752625003814, 5.693004768154432, 5.607808887124169]],\n",
       "  ['TPI-1 0m', [0.3584705286334408, 0.27722060278542376, 0.23754092746882788]],\n",
       "  ['TPI-1 5m', [4.041507552190782, 4.010768823462263, 3.9468349597947006]],\n",
       "  ['N22-IN-1 0m',\n",
       "   [-0.24737073492741593, -0.3312551824895433, -0.5001413875577294]],\n",
       "  ['N22-IN-1 5m', [3.5368779083398243, 3.331490150995226, 3.466725178945629]]],\n",
       " 'Lck': [['DMSO 0m',\n",
       "   [0.007860196054711662, 0.02571598868084289, -0.03423110826754216]],\n",
       "  ['DMSO 5m', [2.7677808239768673, 2.822678170366835, 2.9990802504757976]],\n",
       "  ['PV 0m', [1.7924304703519385, 1.646146703996754, 1.5395158328757168]],\n",
       "  ['PV 5m', [3.7662544618636087, 3.7430084104450736, 3.680755909971002]],\n",
       "  ['TPI-1 0m',\n",
       "   [-0.005136954434274305, -0.28030268015681886, -0.49329552100034674]],\n",
       "  ['TPI-1 5m', [2.500573358952888, 2.657114374576706, 3.0213009953201473]],\n",
       "  ['N22-IN-1 0m',\n",
       "   [0.09450244572046267, 0.30400257632619326, 0.004725880307521732]],\n",
       "  ['N22-IN-1 5m',\n",
       "   [3.1260366848213925, 2.920613901894839, 2.7993233091962058]]],\n",
       " 'Erk': [['DMSO 0m',\n",
       "   [0.4071869828705559, -0.21888221042121267, -0.29570969990537865]],\n",
       "  ['DMSO 5m', [5.294978531840551, 5.006538959355651, 5.3799250641450715]],\n",
       "  ['PV 0m', [3.801059120572111, 3.6292738129265456, 3.590322160068959]],\n",
       "  ['PV 5m', [6.789484417374702, 6.6537896304400554, 6.5751502140934805]],\n",
       "  ['TPI-1 0m',\n",
       "   [-1.0768309309619548, -0.9777354995258117, -1.2932347310035492]],\n",
       "  ['TPI-1 5m', [5.247242154458616, 5.015568487606776, 4.883342190572411]],\n",
       "  ['N22-IN-1 0m',\n",
       "   [0.36723795153817534, 0.5884949374577375, 0.4496166680303769]],\n",
       "  ['N22-IN-1 5m', [6.454877294294365, 6.410740830787886, 6.56773628607047]]]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_norm_merge(\"./phosphatase\", group_labels = ppase_groups, target_strs = targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".whores",
   "language": "python",
   "name": ".whores"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
